name: SMART Compliance Tests (Inferno)

on:
  # Manual trigger
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: true
        default: 'smart_stu2_2'
        type: choice
        options:
          - smart_stu2_2
          - smart_stu2
          - smart_stu1
      test_stage:
        description: 'Test stage config to use'
        required: false
        default: 'alpha'
        type: choice
        options:
          - alpha
          - beta
          - production
  
  # Called by other workflows (alpha, beta, production releases)
  workflow_call:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: false
        type: string
        default: 'smart_stu2_2'
      test_stage:
        description: 'Test stage config to use'
        required: false
        type: string
        default: 'alpha'
    outputs:
      passed:
        description: 'Number of passed tests'
        value: ${{ jobs.smart-compliance-test.outputs.passed }}
      failed:
        description: 'Number of failed tests'
        value: ${{ jobs.smart-compliance-test.outputs.failed }}
      status:
        description: 'Overall test status'
        value: ${{ jobs.smart-compliance-test.outputs.status }}
  
  # Run on releases
  push:
    tags:
      - 'v*'
  # Scheduled weekly run
  schedule:
    - cron: '0 6 * * 1'  # Every Monday at 6 AM UTC

permissions:
  contents: write  # Required to commit test reports

env:
  TEST_STAGE: ${{ inputs.test_stage || 'alpha' }}

jobs:
  smart-compliance-test:
    name: SMART ${{ inputs.test_suite || 'STU2.2' }} Compliance (${{ inputs.test_stage || 'alpha' }})
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    outputs:
      passed: ${{ steps.inferno-tests.outputs.passed }}
      failed: ${{ steps.inferno-tests.outputs.failed }}
      status: ${{ steps.inferno-tests.outcome }}
    
    services:
      postgres:
        image: postgres:17-alpine
        env:
          POSTGRES_USER: keycloak
          POSTGRES_PASSWORD: keycloak
          POSTGRES_DB: keycloak
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      
      # Inferno's postgres
      inferno-db:
        image: postgres:17-alpine
        env:
          POSTGRES_USER: inferno
          POSTGRES_PASSWORD: inferno
          POSTGRES_DB: inferno
        ports:
          - 5433:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 5s
          --health-timeout 5s
          --health-retries 5
      
      # Redis for Inferno
      redis:
        image: redis:8-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 5s
          --health-timeout 5s
          --health-retries 5
      
      # HAPI FHIR Server - standard R4 test server
      # Note: HAPI takes ~35 seconds to start. We use a simple TCP check.
      hapi-fhir:
        image: hapiproject/hapi:v8.6.0-1
        ports:
          - 8081:8080
        env:
          hapi.fhir.default_encoding: json
          hapi.fhir.fhir_version: R4

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Load test configuration
        id: config
        run: |
          CONFIG_FILE="testing/${{ env.TEST_STAGE }}/inferno-config.json"
          echo "Loading config from: $CONFIG_FILE"
          
          if [ ! -f "$CONFIG_FILE" ]; then
            echo "ERROR: Config file not found: $CONFIG_FILE"
            exit 1
          fi
          
          # Extract values from config
          INFERNO_URL=$(jq -r '.inferno.url' "$CONFIG_FILE")
          TEST_SUITE=$(jq -r '.inferno.test_suite // "smart_stu2_2"' "$CONFIG_FILE")
          CLIENT_ID=$(jq -r '.client.client_id' "$CONFIG_FILE")
          KC_USERNAME=$(jq -r '.test_user.username' "$CONFIG_FILE")
          KC_PASSWORD=$(jq -r '.test_user.password' "$CONFIG_FILE")
          KC_REALM=$(jq -r '.keycloak.realm' "$CONFIG_FILE")
          KC_PORT=$(jq -r '.keycloak.port' "$CONFIG_FILE")
          BACKEND_PORT=$(jq -r '.backend.port' "$CONFIG_FILE")
          FHIR_PORT=$(jq -r '.fhir_server.port' "$CONFIG_FILE")
          
          # Override test_suite if provided via input
          if [ -n "${{ inputs.test_suite }}" ]; then
            TEST_SUITE="${{ inputs.test_suite }}"
          fi
          
          # Set outputs for later steps
          echo "inferno_url=$INFERNO_URL" >> $GITHUB_OUTPUT
          echo "test_suite=$TEST_SUITE" >> $GITHUB_OUTPUT
          echo "client_id=$CLIENT_ID" >> $GITHUB_OUTPUT
          echo "kc_username=$KC_USERNAME" >> $GITHUB_OUTPUT
          echo "kc_password=$KC_PASSWORD" >> $GITHUB_OUTPUT
          echo "kc_realm=$KC_REALM" >> $GITHUB_OUTPUT
          echo "kc_port=$KC_PORT" >> $GITHUB_OUTPUT
          echo "backend_port=$BACKEND_PORT" >> $GITHUB_OUTPUT
          echo "fhir_port=$FHIR_PORT" >> $GITHUB_OUTPUT
          
          echo "✓ Configuration loaded from $CONFIG_FILE"
          echo "  Test Suite: $TEST_SUITE"
          echo "  Client ID: $CLIENT_ID"
          echo "  Keycloak Realm: $KC_REALM"

      # Cache Docker images to speed up workflow
      - name: Cache Docker images
        uses: actions/cache@v4
        id: docker-cache
        with:
          path: /tmp/docker-images
          key: docker-images-keycloak-26.0.5

      - name: Load cached Docker images
        if: steps.docker-cache.outputs.cache-hit == 'true'
        run: |
          if [ -f /tmp/docker-images/keycloak.tar ]; then
            echo "Loading cached Keycloak image..."
            docker load -i /tmp/docker-images/keycloak.tar
            echo "✓ Keycloak image loaded from cache"
          fi

      - name: Pull and cache Keycloak image
        if: steps.docker-cache.outputs.cache-hit != 'true'
        run: |
          echo "Pulling Keycloak image (will be cached for next run)..."
          docker pull quay.io/keycloak/keycloak:26.0.5
          mkdir -p /tmp/docker-images
          docker save quay.io/keycloak/keycloak:26.0.5 -o /tmp/docker-images/keycloak.tar
          echo "✓ Keycloak image pulled and saved for caching"

      - name: Setup Bun
        uses: oven-sh/setup-bun@v2
        with:
          bun-version: latest

      - name: Install dependencies
        run: bun install

      - name: Build Backend
        run: |
          cd backend
          bun run build

      # Start Keycloak with realm import
      - name: Start Keycloak
        run: |
          # Copy realm export to a temp location for mounting
          mkdir -p /tmp/keycloak-import
          cp keycloak/realm-export.json /tmp/keycloak-import/
          
          docker run -d \
            --name keycloak \
            --network host \
            -v /tmp/keycloak-import:/opt/keycloak/data/import \
            -e KEYCLOAK_ADMIN=admin \
            -e KEYCLOAK_ADMIN_PASSWORD=admin \
            -e KC_DB=postgres \
            -e KC_DB_URL=jdbc:postgresql://localhost:5432/keycloak \
            -e KC_DB_USERNAME=keycloak \
            -e KC_DB_PASSWORD=keycloak \
            -e KC_HEALTH_ENABLED=true \
            -e KC_HTTP_ENABLED=true \
            -e KC_HOSTNAME_STRICT=false \
            quay.io/keycloak/keycloak:26.0.5 \
            start-dev --import-realm
          
          # Wait for Keycloak to be ready
          # Note: Health endpoints return 404 in dev mode, check the realm endpoint instead
          echo "Waiting for Keycloak..."
          for i in {1..60}; do
            # Check if Keycloak is responding on the master realm
            HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8080/realms/master 2>/dev/null || echo "000")
            if [ "$HTTP_CODE" = "200" ]; then
              echo "Keycloak is ready! (HTTP $HTTP_CODE)"
              break
            fi
            echo "Attempt $i/60... (HTTP $HTTP_CODE)"
            sleep 2
          done
          
          # Verify realm was imported
          sleep 5
          echo "Checking realm..."
          TOKEN=$(curl -s -X POST "http://localhost:8080/realms/master/protocol/openid-connect/token" \
            -H "Content-Type: application/x-www-form-urlencoded" \
            -d "grant_type=password&client_id=admin-cli&username=admin&password=admin" | jq -r '.access_token')
          
          REALMS=$(curl -s "http://localhost:8080/admin/realms" -H "Authorization: Bearer $TOKEN" | jq -r '.[].realm')
          echo "Available realms: $REALMS"
          
          if echo "$REALMS" | grep -q "proxy-smart"; then
            echo "✓ proxy-smart realm found!"
          else
            echo "ERROR: proxy-smart realm not found! Check realm-export.json import."
            docker logs keycloak | tail -50
            exit 1
          fi

      # Wait for HAPI FHIR to be ready (takes ~35 seconds to start)
      - name: Wait for HAPI FHIR
        run: |
          echo "Waiting for HAPI FHIR server to be ready..."
          for i in {1..60}; do
            if curl -sf http://localhost:8081/fhir/metadata > /dev/null 2>&1; then
              echo "✓ HAPI FHIR is ready!"
              curl -s http://localhost:8081/fhir/metadata | jq -r '.fhirVersion' | xargs -I{} echo "  FHIR Version: {}"
              exit 0
            fi
            echo "Attempt $i/60 - waiting for HAPI FHIR..."
            sleep 2
          done
          echo "ERROR: HAPI FHIR failed to start in time"
          exit 1

      # Seed HAPI FHIR with test resources required for fhirUser claim validation
      - name: Seed FHIR Test Resources
        run: |
          echo "Seeding HAPI FHIR with test resources..."
          
          # Create Practitioner resource for fhirUser claim
          # This matches the fhirUser claim in Keycloak realm-export.json
          curl -sf -X PUT "http://localhost:8081/fhir/Practitioner/example-practitioner" \
            -H "Content-Type: application/fhir+json" \
            -d '{
              "resourceType": "Practitioner",
              "id": "example-practitioner",
              "identifier": [{
                "system": "http://example.org/practitioners",
                "value": "doctor"
              }],
              "active": true,
              "name": [{
                "family": "Doctor",
                "given": ["Test"],
                "prefix": ["Dr."]
              }],
              "telecom": [{
                "system": "email",
                "value": "doctor@example.com"
              }]
            }' && echo "✓ Created Practitioner/example-practitioner"
          
          # Create a test Patient for launch/patient scope
          curl -sf -X PUT "http://localhost:8081/fhir/Patient/test-patient" \
            -H "Content-Type: application/fhir+json" \
            -d '{
              "resourceType": "Patient",
              "id": "test-patient",
              "identifier": [{
                "system": "http://example.org/patients",
                "value": "12345"
              }],
              "active": true,
              "name": [{
                "family": "Test",
                "given": ["Patient"]
              }],
              "gender": "unknown",
              "birthDate": "1990-01-01"
            }' && echo "✓ Created Patient/test-patient"
          
          echo "✓ FHIR test resources seeded successfully"

      # Start the application
      - name: Start Application
        run: |
          cd backend
          bun run start &
          APP_PID=$!
          echo "app_pid=$APP_PID" >> $GITHUB_ENV
          
          # Wait for app to be ready
          echo "Waiting for application..."
          for i in {1..30}; do
            if curl -sf http://localhost:8445/health; then
              echo "Application is ready!"
              break
            fi
            echo "Attempt $i/30..."
            sleep 2
          done
        env:
          NODE_ENV: production
          KEYCLOAK_BASE_URL: http://localhost:8080
          KEYCLOAK_REALM: proxy-smart
          # Point to HAPI FHIR server running in GitHub Actions service container
          FHIR_SERVER_BASE: http://localhost:8081/fhir

      # Setup Node.js for Playwright
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install Playwright
        run: |
          # Install Playwright in a separate directory to avoid workspace package.json issues
          mkdir -p /tmp/playwright-setup
          cd /tmp/playwright-setup
          npm init -y
          npm install playwright
          npx playwright install chromium --with-deps
          # Copy playwright to workspace node_modules for script access
          mkdir -p $GITHUB_WORKSPACE/node_modules
          cp -r node_modules/playwright* $GITHUB_WORKSPACE/node_modules/ || true

      - name: Setup Ruby
        uses: ruby/setup-ruby@v1
        with:
          ruby-version: '3.3'
          bundler-cache: false

      - name: Setup Inferno
        run: |
          git clone https://github.com/inferno-framework/smart-app-launch-test-kit.git inferno
          cd inferno
          bundle install
          
          # Setup database
          export DATABASE_URL="postgresql://inferno:inferno@localhost:5433/inferno"
          export REDIS_URL="redis://localhost:6379"
          bundle exec rake db:migrate || bundle exec rake db:setup || true

      - name: Start Inferno
        run: |
          cd inferno
          export DATABASE_URL="postgresql://inferno:inferno@localhost:5433/inferno"
          export REDIS_URL="redis://localhost:6379"
          
          # Start Sidekiq worker for background job processing (test runs)
          # Must use -r ./worker.rb to load Inferno's job classes
          bundle exec sidekiq -r ./worker.rb &
          SIDEKIQ_PID=$!
          echo "Started Sidekiq worker (PID: $SIDEKIQ_PID)"
          
          # Give Sidekiq a moment to connect to Redis
          sleep 2
          
          # Start Inferno web server in background
          bundle exec puma -p 4567 &
          PUMA_PID=$!
          echo "Started Puma server (PID: $PUMA_PID)"
          
          # Wait for Inferno to be ready
          echo "Waiting for Inferno..."
          for i in {1..60}; do
            if curl -sf http://localhost:4567 > /dev/null 2>&1; then
              echo "Inferno is ready!"
              break
            fi
            echo "Attempt $i/60..."
            sleep 5
          done

      # Register test client in Keycloak
      - name: Verify Keycloak Setup
        run: |
          # Get admin token
          TOKEN=$(curl -s -X POST "http://localhost:8080/realms/master/protocol/openid-connect/token" \
            -H "Content-Type: application/x-www-form-urlencoded" \
            -d "grant_type=password" \
            -d "client_id=admin-cli" \
            -d "username=admin" \
            -d "password=admin" | jq -r '.access_token')
          
          echo "Admin token obtained: ${TOKEN:0:20}..."
          
          # Verify realm was imported from realm-export.json
          REALM_CHECK=$(curl -s -o /dev/null -w "%{http_code}" \
            "http://localhost:8080/admin/realms/proxy-smart" \
            -H "Authorization: Bearer $TOKEN")
          
          if [ "$REALM_CHECK" = "200" ]; then
            echo "✓ proxy-smart realm exists"
          else
            echo "ERROR: proxy-smart realm not found! Check realm-export.json import."
            exit 1
          fi
          
          # Verify inferno-test-client exists (from realm-export.json)
          CLIENT_CHECK=$(curl -s "http://localhost:8080/admin/realms/proxy-smart/clients?clientId=inferno-test-client" \
            -H "Authorization: Bearer $TOKEN" | jq 'length')
          
          if [ "$CLIENT_CHECK" -gt 0 ]; then
            echo "✓ inferno-test-client exists"
          else
            echo "ERROR: inferno-test-client not found! Check realm-export.json"
            exit 1
          fi
          
          # Verify testuser exists (from realm-export.json)
          USER_CHECK=$(curl -s "http://localhost:8080/admin/realms/proxy-smart/users?username=testuser" \
            -H "Authorization: Bearer $TOKEN" | jq 'length')
          
          if [ "$USER_CHECK" -gt 0 ]; then
            echo "✓ testuser exists"
          else
            echo "ERROR: testuser not found! Check realm-export.json"
            exit 1
          fi
          
          # Verify SMART scopes exist
          echo "Checking SMART client scopes..."
          SCOPES=$(curl -s "http://localhost:8080/admin/realms/proxy-smart/client-scopes" \
            -H "Authorization: Bearer $TOKEN" | jq -r '.[].name' | sort)
          echo "Available client scopes:"
          echo "$SCOPES"
          
          # Check for key SMART scopes
          if echo "$SCOPES" | grep -q "launch/patient"; then
            echo "✓ SMART scopes configured"
          else
            echo "WARNING: SMART scopes not found - they should be in realm-export.json"
          fi
          
          # Verify offline_access role exists (from realm-export.json)
          echo ""
          echo "Verifying offline_access role..."
          OFFLINE_ROLE=$(curl -s "http://localhost:8080/admin/realms/proxy-smart/roles/offline_access" \
            -H "Authorization: Bearer $TOKEN")
          OFFLINE_ROLE_ID=$(echo "$OFFLINE_ROLE" | jq -r '.id')
          
          if [ "$OFFLINE_ROLE_ID" != "null" ] && [ -n "$OFFLINE_ROLE_ID" ]; then
            echo "✓ offline_access role exists (ID: $OFFLINE_ROLE_ID)"
          else
            echo "WARNING: offline_access role not found - should be in realm-export.json"
          fi
          
          # Verify testuser has offline_access role
          TESTUSER_ID=$(curl -s "http://localhost:8080/admin/realms/proxy-smart/users?username=testuser" \
            -H "Authorization: Bearer $TOKEN" | jq -r '.[0].id')
          USER_ROLES=$(curl -s "http://localhost:8080/admin/realms/proxy-smart/users/$TESTUSER_ID/role-mappings/realm" \
            -H "Authorization: Bearer $TOKEN" | jq -r '.[].name')
          echo "testuser roles: $USER_ROLES"
          
          if echo "$USER_ROLES" | grep -q "offline_access"; then
            echo "✓ testuser has offline_access role"
          else
            echo "WARNING: testuser missing offline_access role - should be in realm-export.json"
          fi
          
          # Verify doctor user has offline_access role
          DOCTOR_ID=$(curl -s "http://localhost:8080/admin/realms/proxy-smart/users?username=doctor" \
            -H "Authorization: Bearer $TOKEN" | jq -r '.[0].id')
          
          if [ "$DOCTOR_ID" != "null" ] && [ -n "$DOCTOR_ID" ]; then
            DOCTOR_ROLES=$(curl -s "http://localhost:8080/admin/realms/proxy-smart/users/$DOCTOR_ID/role-mappings/realm" \
              -H "Authorization: Bearer $TOKEN" | jq -r '.[].name')
            echo "doctor roles: $DOCTOR_ROLES"
            
            if echo "$DOCTOR_ROLES" | grep -q "offline_access"; then
              echo "✓ doctor has offline_access role"
            else
              echo "WARNING: doctor missing offline_access role - should be in realm-export.json"
            fi
          fi
          
          echo ""
          echo "=== Keycloak setup verified ==="

      # Run Inferno tests via Playwright automation
      - name: Run SMART Compliance Tests
        id: inferno-tests
        continue-on-error: true
        run: |
          set +e  # Disable exit on error for robust handling
          
          echo "=== SMART 2.2.0 Compliance Testing with Inferno ==="
          echo ""
          
          # Get FHIR server URL from our proxy
          echo "### Step 0: Discovering FHIR Servers ###"
          SERVERS=$(curl -s "http://localhost:8445/fhir-servers" 2>&1)
          echo "Available FHIR servers:"
          echo "$SERVERS" | jq '.' 2>/dev/null || echo "$SERVERS"
          
          # Get the first server's endpoints
          SMART_CONFIG_URL=$(echo "$SERVERS" | jq -r '.servers[0].endpoints.smartConfig // empty' 2>/dev/null)
          BASE_FHIR_URL=$(echo "$SERVERS" | jq -r '.servers[0].endpoints.base // empty' 2>/dev/null)
          
          if [ -z "$SMART_CONFIG_URL" ] || [ "$SMART_CONFIG_URL" = "null" ]; then
            echo "::warning::No FHIR servers configured - cannot test SMART configuration"
            echo "## SMART Compliance Tests - SKIPPED" >> $GITHUB_STEP_SUMMARY
            echo "No FHIR servers configured." >> $GITHUB_STEP_SUMMARY
            echo "passed=0" >> $GITHUB_OUTPUT
            echo "failed=0" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          echo ""
          echo "Using SMART config URL: $SMART_CONFIG_URL"
          echo "Using FHIR base URL: $BASE_FHIR_URL"
          
          # Step 1: Quick validation of SMART configuration
          echo ""
          echo "### Step 1: Quick SMART Configuration Validation ###"
          SMART_CONFIG=$(curl -s "$SMART_CONFIG_URL" 2>&1)
          echo "$SMART_CONFIG" | jq '.'
          
          # Check required fields
          AUTH_EP=$(echo "$SMART_CONFIG" | jq -r '.authorization_endpoint // empty')
          TOKEN_EP=$(echo "$SMART_CONFIG" | jq -r '.token_endpoint // empty')
          
          if [ -z "$AUTH_EP" ] || [ -z "$TOKEN_EP" ]; then
            echo "::error::Missing required SMART endpoints"
            echo "## SMART Compliance Tests - FAILED" >> $GITHUB_STEP_SUMMARY
            echo "Missing authorization_endpoint or token_endpoint" >> $GITHUB_STEP_SUMMARY
            echo "passed=0" >> $GITHUB_OUTPUT
            echo "failed=1" >> $GITHUB_OUTPUT
            exit 1
          fi
          
          echo "✓ authorization_endpoint: $AUTH_EP"
          echo "✓ token_endpoint: $TOKEN_EP"
          
          # Step 2: Run Inferno tests with Playwright OAuth automation
          echo ""
          echo "### Step 2: Running Inferno Tests with Playwright ###"
          
          # Copy the script to the Playwright directory and run it from there
          cp .github/scripts/inferno-oauth-automation.js /tmp/playwright-setup/
          cd /tmp/playwright-setup
          node inferno-oauth-automation.js 2>&1 | tee $GITHUB_WORKSPACE/inferno-output.log
          INFERNO_EXIT_CODE=${PIPESTATUS[0]}
          cd $GITHUB_WORKSPACE
          
          # Parse results from the log
          if grep -q "PASS:" inferno-output.log; then
            PASSED=$(grep -c "✓ PASS:" inferno-output.log || echo "0")
            FAILED=$(grep -c "✗ FAIL:" inferno-output.log || echo "0")
          else
            PASSED=0
            FAILED=0
          fi
          
          # Write summary
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## SMART 2.2.0 Compliance Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "$INFERNO_EXIT_CODE" -eq 0 ]; then
            echo "**Status: ✓ PASSED**" >> $GITHUB_STEP_SUMMARY
          else
            echo "**Status: ✗ FAILED**" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "- Passed: $PASSED" >> $GITHUB_STEP_SUMMARY
          echo "- Failed: $FAILED" >> $GITHUB_STEP_SUMMARY
          echo "- Test Stage: ${{ env.TEST_STAGE }}" >> $GITHUB_STEP_SUMMARY
          
          # Include FHIR server info (discovered from SMART config)
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### FHIR Server Configuration" >> $GITHUB_STEP_SUMMARY
          FHIR_VERSION=$(echo "$SMART_CONFIG" | jq -r '.fhirVersion // "R4"')
          echo "- FHIR Version: $FHIR_VERSION" >> $GITHUB_STEP_SUMMARY
          echo "- Authorization Endpoint: $AUTH_EP" >> $GITHUB_STEP_SUMMARY
          echo "- Token Endpoint: $TOKEN_EP" >> $GITHUB_STEP_SUMMARY
          
          # Set outputs
          echo "passed=$PASSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          
          exit $INFERNO_EXIT_CODE
        env:
          # All values loaded from testing/$TEST_STAGE/inferno-config.json
          INFERNO_URL: ${{ steps.config.outputs.inferno_url }}
          FHIR_SERVER_URL: http://localhost:${{ steps.config.outputs.backend_port }}/proxy-smart-backend/hapi-fhir-server/R4
          TEST_SUITE: ${{ steps.config.outputs.test_suite }}
          CLIENT_ID: ${{ steps.config.outputs.client_id }}
          KC_USERNAME: ${{ steps.config.outputs.kc_username }}
          KC_PASSWORD: ${{ steps.config.outputs.kc_password }}

      # Save test results
      - name: Save Test Results
        if: always()
        run: |
          mkdir -p test-results
          
          # Discover servers and get SMART config URL
          SERVERS=$(curl -s "http://localhost:8445/fhir-servers" 2>&1)
          SMART_CONFIG_URL=$(echo "$SERVERS" | jq -r '.servers[0].endpoints.smartConfig // empty' 2>/dev/null)
          METADATA_URL=$(echo "$SERVERS" | jq -r '.servers[0].endpoints.metadata // empty' 2>/dev/null)
          
          # Save server discovery info
          echo "$SERVERS" > test-results/fhir-servers.json
          
          # Save SMART configuration if URL available
          if [ -n "$SMART_CONFIG_URL" ] && [ "$SMART_CONFIG_URL" != "null" ]; then
            curl -s "$SMART_CONFIG_URL" > test-results/smart-configuration.json 2>/dev/null || echo "{}" > test-results/smart-configuration.json
          else
            echo "{\"note\": \"No FHIR servers configured\"}" > test-results/smart-configuration.json
          fi
          
          # Save FHIR metadata if URL available
          if [ -n "$METADATA_URL" ] && [ "$METADATA_URL" != "null" ]; then
            curl -s "$METADATA_URL" > test-results/fhir-metadata.json 2>/dev/null || echo "{}" > test-results/fhir-metadata.json
          else
            echo "{\"note\": \"No FHIR servers configured\"}" > test-results/fhir-metadata.json
          fi
          
          # Save Inferno test output
          cp inferno-output.log test-results/inferno-output.log 2>/dev/null || true
          
          # Save Playwright screenshots if any
          cp oauth-error.png test-results/oauth-error.png 2>/dev/null || true
          
          # Also save service logs
          docker logs keycloak > test-results/keycloak.log 2>&1 || true

      - name: Upload Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: inferno-test-results-${{ env.TEST_STAGE }}
          path: test-results/
          retention-days: 30

      # Commit test report to repository
      - name: Commit Test Report
        if: always()
        run: |
          # Create report directory
          REPORT_DIR="testing/${TEST_STAGE}/report"
          mkdir -p "$REPORT_DIR"
          
          # Copy test results to report directory
          cp -r test-results/* "$REPORT_DIR/" 2>/dev/null || true
          
          # Create summary report
          cat > "$REPORT_DIR/summary.json" << EOF
          {
            "test_suite": "${TEST_SUITE}",
            "test_stage": "${TEST_STAGE}",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "commit": "${{ github.sha }}",
            "run_id": "${{ github.run_id }}",
            "run_url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}",
            "passed": ${{ steps.inferno-tests.outputs.passed || 0 }},
            "failed": ${{ steps.inferno-tests.outputs.failed || 0 }},
            "status": "${{ steps.inferno-tests.outcome || 'unknown' }}"
          }
          EOF
          
          # Configure git
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          # Save report files before branch switch
          cp -r "$REPORT_DIR" /tmp/report-backup
          
          # Checkout develop branch and pull latest (to avoid race conditions with version updates)
          git fetch origin develop
          git checkout develop
          git pull origin develop --rebase || true
          
          # Restore and add report directory after branch switch
          cp -r /tmp/report-backup/* "$REPORT_DIR/"
          git add "$REPORT_DIR"
          git diff --staged --quiet || git commit -m "chore(testing): update ${TEST_STAGE} SMART compliance report [skip ci]
          
          Test Suite: ${TEST_SUITE}
          Passed: ${{ steps.inferno-tests.outputs.passed || 0 }}
          Failed: ${{ steps.inferno-tests.outputs.failed || 0 }}
          Run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          
          # Push changes to develop with retry on conflict
          for i in 1 2 3; do
            if git push origin develop; then
              echo "✓ Report pushed successfully"
              break
            else
              echo "Push failed, retrying after pull..."
              git pull origin develop --rebase
            fi
          done
        env:
          TEST_STAGE: ${{ env.TEST_STAGE }}
          TEST_SUITE: ${{ env.TEST_SUITE }}

      # Cleanup
      - name: Cleanup
        if: always()
        run: |
          docker stop keycloak || true
          docker rm keycloak || true
          pkill -f "bun run start" || true
          pkill -f puma || true
